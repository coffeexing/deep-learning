{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Two Layer Net"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bf7964b4b339707"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "from Data.common.functions import *\n",
    "from Data.common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, \n",
    "                 weight_init_std=0.01):\n",
    "        # Initialization\n",
    "        self.parms = {}\n",
    "        self.parms['W1'] = (weight_init_std * \n",
    "                            np.random.randn(input_size, hidden_size))\n",
    "        self.parms['b1'] = np.zeros(hidden_size)\n",
    "        self.parms['W2'] = (weight_init_std *\n",
    "                            np.random.randn(hidden_size, output_size))\n",
    "        self.parms['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.parms['W1'], self.parms['W2']\n",
    "        b1, b2 = self.parms['b1'], self.parms['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x:input data, t:supervised data\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # x:input data, t:supervised data\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.parms['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.parms['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.parms['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.parms['b2'])\n",
    "        \n",
    "        return grads"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-27T07:00:53.255159500Z",
     "start_time": "2025-08-27T07:00:52.699450400Z"
    }
   },
   "id": "59bda6a9ab3b4f43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc05ce6c3cacc45"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(10,)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "net.parms['W1'].shape  # (784, 100)\n",
    "net.parms['b1'].shape  # (100, )\n",
    "net.parms['W2'].shape  # (100, 10)\n",
    "net.parms['b2'].shape  # (10, )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-27T07:00:53.859488700Z",
     "start_time": "2025-08-27T07:00:53.261158500Z"
    }
   },
   "id": "c55ab6b5ab46e82f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.72468402 -0.70983511 -0.93445922 ...  0.90127001  0.86624931\n",
      "  -0.65456812]\n",
      " [-0.62081255 -0.64288812 -1.45622426 ...  0.79893401 -0.97030728\n",
      "   1.2771739 ]\n",
      " [-0.20687159  0.96433086 -1.09931155 ...  0.117193    0.08211526\n",
      "   3.06650027]\n",
      " ...\n",
      " [-0.36403049  1.62750829 -0.95608975 ...  1.07006293 -0.68585338\n",
      "  -0.93830991]\n",
      " [ 0.04586788  1.31034217 -0.65691974 ... -0.51013793 -0.31254408\n",
      "  -0.28989249]\n",
      " [ 0.73478601 -0.98877858 -0.21029173 ...  0.49109575 -1.14603968\n",
      "   0.44714194]] [[0.10656946 0.09885364 0.10197975 0.10385849 0.10035054 0.10011378\n",
      "  0.10420243 0.09281858 0.09156807 0.09968526]\n",
      " [0.1062695  0.0986481  0.10081077 0.10468338 0.10016795 0.09927898\n",
      "  0.10445911 0.09194888 0.09436491 0.09936843]\n",
      " [0.10726769 0.09876887 0.10153055 0.10384619 0.09981575 0.09950744\n",
      "  0.10400528 0.09267687 0.09338771 0.09919365]\n",
      " [0.10592199 0.09755883 0.1024035  0.10368813 0.10035241 0.09917274\n",
      "  0.10357077 0.09276747 0.0941277  0.10043646]\n",
      " [0.10607726 0.09908238 0.10263069 0.1051033  0.09996743 0.09945831\n",
      "  0.10261228 0.09247417 0.09294894 0.09964524]\n",
      " [0.10681772 0.09758519 0.10216581 0.10514131 0.09939891 0.09966786\n",
      "  0.10418545 0.09309651 0.09236074 0.09958049]\n",
      " [0.1068803  0.09833122 0.10253185 0.10386939 0.10085139 0.09919671\n",
      "  0.10312826 0.09262646 0.09355469 0.09902973]\n",
      " [0.10671397 0.0990929  0.10000561 0.10397733 0.10089718 0.10027182\n",
      "  0.10352036 0.09220606 0.09264967 0.10066511]\n",
      " [0.10673165 0.09846659 0.10109887 0.10556948 0.09848393 0.09947247\n",
      "  0.10352921 0.09277315 0.09317503 0.10069962]\n",
      " [0.10689404 0.09803055 0.10190204 0.10494134 0.09961555 0.0994056\n",
      "  0.10469681 0.09355143 0.09228808 0.09867456]\n",
      " [0.10621913 0.09856497 0.10152183 0.10441128 0.09904239 0.09998933\n",
      "  0.10351209 0.09239919 0.0933984  0.10094139]\n",
      " [0.10711981 0.09890689 0.10108177 0.10414794 0.10070432 0.09980832\n",
      "  0.10415962 0.09147372 0.09298901 0.09960858]\n",
      " [0.10715651 0.09723886 0.10221131 0.10382046 0.09917398 0.10058614\n",
      "  0.10384972 0.09247543 0.09365556 0.09983202]\n",
      " [0.10636392 0.09862357 0.10159052 0.1037393  0.10020694 0.10008854\n",
      "  0.10407651 0.09209926 0.092946   0.10026544]\n",
      " [0.1060911  0.09788695 0.10229418 0.10449217 0.10093553 0.09946407\n",
      "  0.1045731  0.0917995  0.09370467 0.09875874]\n",
      " [0.10820826 0.09834309 0.10100799 0.1049502  0.09925223 0.09912736\n",
      "  0.10357509 0.09207641 0.09326402 0.10019535]\n",
      " [0.10691294 0.09839812 0.10116978 0.10396783 0.09978501 0.09896481\n",
      "  0.10394779 0.09322914 0.09397765 0.09964693]\n",
      " [0.10549847 0.09836546 0.10201881 0.10432379 0.10046082 0.09895857\n",
      "  0.10412004 0.09274509 0.09384623 0.09966274]\n",
      " [0.10677851 0.09735727 0.10157758 0.10406619 0.0999419  0.10057579\n",
      "  0.10447065 0.09333324 0.093469   0.09842987]\n",
      " [0.10647384 0.09628447 0.10171324 0.10522567 0.10029811 0.10009959\n",
      "  0.10379087 0.09302179 0.093816   0.09927642]\n",
      " [0.1076331  0.0981285  0.10167747 0.10406511 0.10005586 0.10025833\n",
      "  0.10454872 0.09140577 0.0926683  0.09955884]\n",
      " [0.10742646 0.09790552 0.10167817 0.10331792 0.09984924 0.10049298\n",
      "  0.1035702  0.09209211 0.0937082  0.09995921]\n",
      " [0.10771497 0.0987006  0.10115592 0.1031909  0.1004468  0.09941605\n",
      "  0.10317158 0.09215257 0.09365591 0.10039468]\n",
      " [0.10717666 0.09761308 0.1012638  0.10417209 0.1007529  0.099588\n",
      "  0.10500676 0.09293641 0.09268357 0.09880672]\n",
      " [0.10698826 0.09799824 0.10060725 0.1043201  0.10073595 0.10013124\n",
      "  0.10404061 0.09265602 0.09335711 0.09916522]\n",
      " [0.10703749 0.09821624 0.10195528 0.1042467  0.10071353 0.09941068\n",
      "  0.10329535 0.09180192 0.09325723 0.10006557]\n",
      " [0.10766995 0.0982698  0.1009505  0.10463937 0.09991934 0.09979168\n",
      "  0.10364095 0.09336833 0.09317162 0.09857847]\n",
      " [0.10761007 0.09829899 0.10195399 0.10362871 0.10126905 0.0985972\n",
      "  0.10385339 0.09218446 0.09298556 0.09961859]\n",
      " [0.10757815 0.09854573 0.10152179 0.1042558  0.09985575 0.10073368\n",
      "  0.10325122 0.09215424 0.09237353 0.09973011]\n",
      " [0.10715374 0.09875293 0.10215664 0.10475313 0.09941887 0.09905225\n",
      "  0.10347829 0.09254953 0.09320333 0.0994813 ]\n",
      " [0.10698451 0.09759187 0.10204186 0.10353056 0.10102245 0.10076635\n",
      "  0.1020529  0.09298247 0.09380249 0.09922453]\n",
      " [0.10788981 0.09861774 0.10091929 0.10464225 0.10024667 0.09944911\n",
      "  0.10369348 0.09163242 0.09351177 0.09939746]\n",
      " [0.10719383 0.09897822 0.10206061 0.10318631 0.10036178 0.10026592\n",
      "  0.10327939 0.09164661 0.09278281 0.10024453]\n",
      " [0.10771753 0.09877303 0.10016109 0.10427532 0.09994989 0.09932549\n",
      "  0.10433119 0.09298454 0.09364624 0.09883569]\n",
      " [0.106951   0.09916578 0.10207291 0.10415325 0.10053519 0.09993372\n",
      "  0.10301262 0.09188444 0.09255961 0.09973147]\n",
      " [0.1061339  0.09819782 0.102078   0.10378594 0.10022032 0.09798335\n",
      "  0.10447926 0.09263357 0.09484947 0.09963836]\n",
      " [0.10753599 0.09870043 0.10273899 0.10480935 0.10064631 0.09933436\n",
      "  0.10426139 0.09189626 0.0915908  0.09848613]\n",
      " [0.10783666 0.09804002 0.10169009 0.10533342 0.09924311 0.09945463\n",
      "  0.10297223 0.09183251 0.0933063  0.10029104]\n",
      " [0.10708344 0.09818988 0.10208542 0.10504355 0.10030174 0.09819375\n",
      "  0.10342288 0.09164664 0.09424974 0.09978297]\n",
      " [0.10718241 0.09832316 0.10178968 0.10388756 0.10276033 0.09987767\n",
      "  0.10363231 0.09206884 0.09257364 0.0979044 ]\n",
      " [0.10851728 0.09934869 0.10098308 0.10357678 0.09933395 0.09932891\n",
      "  0.10441148 0.09254306 0.09280489 0.09915187]\n",
      " [0.10626354 0.09789602 0.10118044 0.10475364 0.09989749 0.0994567\n",
      "  0.1046243  0.09252814 0.09373382 0.09966591]\n",
      " [0.10824712 0.09935682 0.10099408 0.10333886 0.09942417 0.10010041\n",
      "  0.10321004 0.0930666  0.09308919 0.09917272]\n",
      " [0.10678157 0.09763115 0.10269791 0.10382133 0.0997759  0.09953882\n",
      "  0.1045917  0.09201833 0.09369083 0.09945248]\n",
      " [0.10742541 0.09816318 0.1009748  0.1038005  0.10065358 0.09999342\n",
      "  0.10340497 0.09215482 0.09270401 0.1007253 ]\n",
      " [0.10657734 0.09816035 0.10114669 0.10543525 0.09943492 0.09968561\n",
      "  0.10423389 0.09315418 0.09336436 0.09880742]\n",
      " [0.10746783 0.09848236 0.10198858 0.10403116 0.09973803 0.09790847\n",
      "  0.10415932 0.09292039 0.09335231 0.09995155]\n",
      " [0.1070738  0.09885804 0.10150561 0.10379694 0.10076954 0.09951273\n",
      "  0.10292841 0.09245381 0.09309443 0.10000668]\n",
      " [0.10671589 0.0983862  0.10117309 0.10394898 0.10086473 0.09903179\n",
      "  0.10472586 0.09207634 0.09338706 0.09969006]\n",
      " [0.10669835 0.09693372 0.10199338 0.10454931 0.10024831 0.09977046\n",
      "  0.10427703 0.0930202  0.09332911 0.09918013]\n",
      " [0.1074091  0.09912142 0.10136392 0.10319799 0.10056025 0.09912982\n",
      "  0.10394639 0.09132815 0.09415315 0.0997898 ]\n",
      " [0.10514325 0.09829463 0.10178133 0.10462778 0.10005263 0.09914128\n",
      "  0.10371119 0.09237597 0.09382884 0.10104312]\n",
      " [0.10704846 0.09856619 0.10123757 0.10404245 0.10060037 0.098851\n",
      "  0.10405726 0.09285829 0.0931884  0.09955001]\n",
      " [0.10774127 0.0982774  0.10171937 0.10486165 0.10028502 0.09807607\n",
      "  0.10396914 0.09250556 0.09478803 0.0977765 ]\n",
      " [0.10695981 0.09810617 0.10110024 0.10442684 0.10115631 0.10003169\n",
      "  0.1045213  0.09184315 0.09248525 0.09936922]\n",
      " [0.10618885 0.09889694 0.10240261 0.10288165 0.10151031 0.0995829\n",
      "  0.1036203  0.09171729 0.09329299 0.09990615]\n",
      " [0.10766515 0.09857169 0.10172404 0.10554266 0.09882206 0.09868097\n",
      "  0.10444289 0.09072604 0.09365646 0.10016806]\n",
      " [0.10568777 0.09874448 0.10236449 0.10391565 0.10096047 0.09807695\n",
      "  0.10361704 0.09257013 0.09371228 0.10035074]\n",
      " [0.10543263 0.09862334 0.10289616 0.10438295 0.09981984 0.09952729\n",
      "  0.1038531  0.0925724  0.09350812 0.09938417]\n",
      " [0.1073079  0.09757683 0.10158742 0.1026607  0.09987788 0.10049761\n",
      "  0.1051908  0.09214657 0.0942181  0.09893618]\n",
      " [0.10608171 0.09835159 0.10244759 0.1038166  0.10067741 0.09892329\n",
      "  0.10551437 0.09174311 0.09254049 0.09990384]\n",
      " [0.10686898 0.09939683 0.10234047 0.10291425 0.10016259 0.09908252\n",
      "  0.10395606 0.09281594 0.09340883 0.09905354]\n",
      " [0.10695924 0.09848227 0.10177007 0.10339043 0.10228739 0.09904202\n",
      "  0.10359299 0.09205337 0.09239594 0.10002629]\n",
      " [0.10544571 0.09682425 0.10186299 0.1044025  0.09973816 0.10068227\n",
      "  0.10473754 0.0940427  0.09266118 0.0996027 ]\n",
      " [0.1073812  0.09855584 0.10229487 0.10317844 0.10082871 0.09888812\n",
      "  0.10388166 0.09190307 0.09426913 0.09881897]\n",
      " [0.10595386 0.09882859 0.10147048 0.10396304 0.10053205 0.10029082\n",
      "  0.10420813 0.09231541 0.09230712 0.10013049]\n",
      " [0.10678411 0.0985625  0.1012302  0.1048107  0.09929927 0.10041066\n",
      "  0.10440296 0.09213052 0.09247759 0.09989148]\n",
      " [0.10757085 0.09827059 0.10183127 0.10449713 0.09976408 0.09950901\n",
      "  0.10439631 0.09261412 0.09178047 0.09976617]\n",
      " [0.10646685 0.09888491 0.10160541 0.10424897 0.09928771 0.09964332\n",
      "  0.10342535 0.09208768 0.09343348 0.10091632]\n",
      " [0.1071397  0.09873194 0.10133028 0.10511722 0.10108647 0.09995392\n",
      "  0.1027094  0.09209686 0.09217256 0.09966165]\n",
      " [0.10821348 0.09851083 0.10107993 0.10321239 0.09962421 0.0996895\n",
      "  0.10450968 0.0926174  0.09424444 0.09829815]\n",
      " [0.10678152 0.09850035 0.1017674  0.10364087 0.10136954 0.09915444\n",
      "  0.10407481 0.09210556 0.09311547 0.09949005]\n",
      " [0.10704492 0.09896516 0.10101052 0.10315613 0.10006777 0.09998334\n",
      "  0.10348111 0.09234529 0.09315599 0.10078976]\n",
      " [0.10697607 0.09835576 0.10149852 0.10446533 0.09995629 0.10148239\n",
      "  0.10401133 0.09276879 0.09229704 0.09818848]\n",
      " [0.10637425 0.09690582 0.10150002 0.10350164 0.10044763 0.10036037\n",
      "  0.1042981  0.09244297 0.09468617 0.09948304]\n",
      " [0.10679908 0.09786019 0.10071412 0.10433764 0.09964009 0.10009616\n",
      "  0.10435595 0.0927966  0.09381779 0.09958237]\n",
      " [0.10678146 0.09819304 0.10046752 0.10318825 0.10037368 0.10008031\n",
      "  0.10384002 0.09242184 0.09496629 0.0996876 ]\n",
      " [0.10639008 0.09704398 0.10104307 0.10473408 0.0991481  0.10062033\n",
      "  0.10365821 0.09269345 0.09400248 0.10066623]\n",
      " [0.10685559 0.09851657 0.10095405 0.10452419 0.10036917 0.0993471\n",
      "  0.1040679  0.09213176 0.09368335 0.09955032]\n",
      " [0.10989108 0.09794114 0.10089893 0.1030198  0.10078503 0.10067007\n",
      "  0.10474762 0.09218465 0.09170267 0.09815901]\n",
      " [0.1078068  0.09875174 0.10158028 0.10389383 0.09985651 0.10035185\n",
      "  0.10277438 0.09220131 0.09235863 0.10042468]\n",
      " [0.10601602 0.09748728 0.1014129  0.10484067 0.10118087 0.09952701\n",
      "  0.10485068 0.09223583 0.09364683 0.0988019 ]\n",
      " [0.10683321 0.09771808 0.10228794 0.10458518 0.10045977 0.09976156\n",
      "  0.10473687 0.091937   0.09295415 0.09872624]\n",
      " [0.10800511 0.098756   0.10112793 0.10397733 0.10102725 0.09917202\n",
      "  0.10334666 0.09230088 0.09311288 0.09917393]\n",
      " [0.10691511 0.09936822 0.10273706 0.10348188 0.09989474 0.09833578\n",
      "  0.10441721 0.09404091 0.09305329 0.09775581]\n",
      " [0.10631883 0.0990901  0.10136165 0.10354835 0.0988162  0.09991922\n",
      "  0.10263235 0.09297032 0.09403922 0.10130375]\n",
      " [0.10689442 0.0992077  0.10154486 0.10301472 0.10038531 0.09902746\n",
      "  0.10407925 0.09240644 0.09332189 0.10011795]\n",
      " [0.1068279  0.09849606 0.10237399 0.10441443 0.10002427 0.09940178\n",
      "  0.10252328 0.09182508 0.0933469  0.10076628]\n",
      " [0.10799907 0.09898107 0.10138579 0.1043591  0.09998951 0.10001725\n",
      "  0.10321999 0.09325865 0.09241518 0.09837439]\n",
      " [0.1079933  0.09871518 0.10126389 0.1046524  0.10010919 0.09850546\n",
      "  0.10405498 0.0910942  0.09278207 0.10082933]\n",
      " [0.10813936 0.09937262 0.10167887 0.1047321  0.09922829 0.09929771\n",
      "  0.10305435 0.09202422 0.09273822 0.09973427]\n",
      " [0.10842768 0.09849408 0.10032988 0.10414963 0.09965472 0.09992757\n",
      "  0.10475649 0.09270799 0.09224449 0.09930748]\n",
      " [0.10681078 0.09925097 0.10083491 0.1037355  0.10134485 0.10069377\n",
      "  0.10382011 0.092855   0.0917078  0.09894629]\n",
      " [0.10727844 0.09839986 0.10198949 0.10441958 0.10121961 0.09968241\n",
      "  0.10326643 0.09168787 0.09253712 0.09951919]\n",
      " [0.10744197 0.09786182 0.10148999 0.1036087  0.09999558 0.10081849\n",
      "  0.10320689 0.09233014 0.09305932 0.10018709]\n",
      " [0.10713798 0.09893798 0.10125748 0.10347753 0.09995286 0.09956366\n",
      "  0.10404421 0.09236578 0.09294272 0.10031981]\n",
      " [0.10681393 0.09856865 0.10163655 0.1042398  0.09928167 0.09979994\n",
      "  0.1034852  0.09346506 0.09300438 0.09970483]\n",
      " [0.10728428 0.09952924 0.10115161 0.10329926 0.10021616 0.09934337\n",
      "  0.10460099 0.09237299 0.09303753 0.09916456]\n",
      " [0.10603092 0.09655652 0.10092353 0.1047029  0.10015361 0.10012231\n",
      "  0.10434499 0.09237895 0.09422061 0.10056567]\n",
      " [0.10603774 0.09843331 0.10181605 0.10488988 0.10046771 0.09989741\n",
      "  0.10386235 0.09179524 0.0930159  0.09978441]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(100, 784)\n",
    "y = net.predict(x)\n",
    "\n",
    "print(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-27T07:00:54.020405Z",
     "start_time": "2025-08-27T07:00:53.865488400Z"
    }
   },
   "id": "94253d6b72342fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(100, 784)\n",
    "t = np.random.randn(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)\n",
    "print(grads['W1'].shape)\n",
    "print(grads['b1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-27T07:03:30.888972600Z",
     "start_time": "2025-08-27T07:00:54.021406600Z"
    }
   },
   "id": "5d6efeb879694860"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
